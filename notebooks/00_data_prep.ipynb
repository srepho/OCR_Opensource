{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Data Preparation\n",
    "\n",
    "This notebook handles:\n",
    "1. Extracting PDFs from zip batches\n",
    "2. Rendering PDF pages to PNG images\n",
    "3. Extracting embedded text as ground truth\n",
    "\n",
    "Run locally before Colab benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure project root is on path\n",
    "PROJECT_ROOT = Path(\".\").resolve().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(PROJECT_ROOT / \"config\" / \"benchmark_config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Show key paths\n",
    "for key, val in config[\"paths\"].items():\n",
    "    print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Extract PDFs from Zip Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_prep.extract_pdfs import extract_all_batches\n",
    "\n",
    "zip_paths = [PROJECT_ROOT / p for p in config[\"zip_batches\"]]\n",
    "pdf_dir = PROJECT_ROOT / config[\"paths\"][\"pdf_dir\"]\n",
    "\n",
    "print(f\"Looking for zip batches: {[str(p) for p in zip_paths]}\")\n",
    "print(f\"Output directory: {pdf_dir}\")\n",
    "\n",
    "pdfs = extract_all_batches(zip_paths, pdf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify extraction\n",
    "import os\n",
    "\n",
    "pdf_files = sorted(pdf_dir.glob(\"*.pdf\"))\n",
    "print(f\"Total PDFs: {len(pdf_files)}\")\n",
    "\n",
    "total_size = sum(f.stat().st_size for f in pdf_files)\n",
    "print(f\"Total size: {total_size / (1024*1024):.1f} MB\")\n",
    "print(f\"Average size: {total_size / len(pdf_files) / 1024:.0f} KB\" if pdf_files else \"No PDFs\")\n",
    "\n",
    "# Show first 10\n",
    "for f in pdf_files[:10]:\n",
    "    print(f\"  {f.name} ({f.stat().st_size / 1024:.0f} KB)\")\n",
    "if len(pdf_files) > 10:\n",
    "    print(f\"  ... and {len(pdf_files) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Render PDF Pages to PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_prep.render_pages import render_all_pdfs\n",
    "\n",
    "image_dir = PROJECT_ROOT / config[\"paths\"][\"image_dir\"]\n",
    "dpi = config[\"rendering\"][\"dpi\"]\n",
    "\n",
    "print(f\"Rendering at {dpi} DPI to {image_dir}\")\n",
    "\n",
    "rendered = render_all_pdfs(\n",
    "    pdf_dir=pdf_dir,\n",
    "    image_dir=image_dir,\n",
    "    dpi=dpi,\n",
    "    max_pages=config[\"rendering\"].get(\"max_pages_per_pdf\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify rendering\n",
    "total_images = sum(len(v) for v in rendered.values())\n",
    "print(f\"Rendered {total_images} page images from {len(rendered)} PDFs\")\n",
    "\n",
    "# Show a sample image\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "sample_stem = list(rendered.keys())[0]\n",
    "sample_images = rendered[sample_stem]\n",
    "if sample_images:\n",
    "    img = Image.open(str(sample_images[0]))\n",
    "    print(f\"Sample: {sample_images[0].name} ({img.size[0]}x{img.size[1]})\")\n",
    "    display(img.resize((400, int(400 * img.size[1] / img.size[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract Embedded Text (Ground Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_prep.extract_embedded_text import extract_all_pdfs\n",
    "\n",
    "gt_text_dir = PROJECT_ROOT / config[\"paths\"][\"embedded_text_dir\"]\n",
    "threshold = config[\"ground_truth\"][\"discrepancy_threshold\"]\n",
    "\n",
    "print(f\"Extracting embedded text to {gt_text_dir}\")\n",
    "print(f\"Discrepancy threshold: {threshold}\")\n",
    "\n",
    "all_meta = extract_all_pdfs(\n",
    "    pdf_dir=pdf_dir,\n",
    "    output_dir=gt_text_dir,\n",
    "    discrepancy_threshold=threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "import json\n",
    "\n",
    "meta_path = gt_text_dir / \"metadata.json\"\n",
    "with open(meta_path) as f:\n",
    "    global_meta = json.load(f)\n",
    "\n",
    "print(f\"Total PDFs: {global_meta['total_pdfs']}\")\n",
    "print(f\"Total pages: {global_meta['total_pages']}\")\n",
    "print(f\"Pages with discrepancy: {global_meta['pages_with_discrepancy']}\")\n",
    "print(f\"Empty pages: {global_meta['empty_pages']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample extracted text\n",
    "sample_text_dir = gt_text_dir / sample_stem\n",
    "sample_text_files = sorted(sample_text_dir.glob(\"page_*.txt\"))\n",
    "if sample_text_files:\n",
    "    text = sample_text_files[0].read_text()\n",
    "    print(f\"Sample GT from {sample_stem}/page_001.txt:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(text[:500])\n",
    "    if len(text) > 500:\n",
    "        print(f\"\\n... ({len(text)} total characters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Data preparation complete. Next steps:\n",
    "- Run `01_build_sample_sets.ipynb` to create stratified sample sets\n",
    "- Then run Colab notebooks for model benchmarking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
